"""
IPGR æµ‹è¯•è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
    python test_ipgr.py --config cfgs/xxx.yaml --ckpt path/to/ckpt.pth

å¯é€‰å‚æ•°:
    --base_alpha: åŸºç¡€ç»†åŒ–å¼ºåº¦ (é»˜è®¤ 0.10)
    --num_iter: è¿­ä»£æ¬¡æ•° (é»˜è®¤ 4)
    --no_ipgr: ä¸ä½¿ç”¨ IPGR åå¤„ç†
"""

import torch
import torch.nn as nn
import os
import sys
import argparse
import numpy as np

sys.path.insert(0, os.getcwd())

from tools import builder
from utils.config import cfg_from_yaml_file
from easydict import EasyDict
from extensions.chamfer_dist import ChamferDistanceL1, ChamferDistanceL2


class IPGR(nn.Module):
    """Iterative Partial-Guided Refinement"""

    def __init__(self, base_alpha=0.10, num_iter=4):
        super().__init__()
        self.base_alpha = base_alpha
        self.num_iter = num_iter

    def forward(self, pred, partial):
        refined = pred
        B, N, _ = pred.shape
        batch_idx = torch.arange(B, device=pred.device).unsqueeze(1).expand(-1, N)

        for i in range(self.num_iter):
            dist = torch.cdist(refined, partial)
            min_dist, min_idx = dist.min(dim=-1)
            nearest = partial[batch_idx, min_idx]

            # è·ç¦»æ„ŸçŸ¥ alpha
            dist_norm = min_dist / (min_dist.max(dim=-1, keepdim=True)[0] + 1e-6)
            alpha = self.base_alpha * (2.0 - dist_norm)

            refined = refined + alpha.unsqueeze(-1) * (nearest - refined)

        return refined


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--ckpt', type=str, required=True, help='æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--base_alpha', type=float, default=0.10, help='IPGR åŸºç¡€ alpha')
    parser.add_argument('--num_iter', type=int, default=4, help='IPGR è¿­ä»£æ¬¡æ•°')
    parser.add_argument('--no_ipgr', action='store_true', help='ä¸ä½¿ç”¨ IPGR')
    args = parser.parse_args()

    print('=' * 70)
    print('IPGR: Iterative Partial-Guided Refinement')
    print('=' * 70)
    print(f'Config: {args.config}')
    print(f'Checkpoint: {args.ckpt}')
    if not args.no_ipgr:
        print(f'IPGR: base_alpha={args.base_alpha}, num_iter={args.num_iter}')
    else:
        print('IPGR: Disabled')
    print('=' * 70)

    # åŠ è½½é…ç½®
    config = cfg_from_yaml_file(args.config)
    config = EasyDict(config)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # æ„å»ºæ•°æ®é›†
    class Args:
        distributed = False
        num_workers = 4

    _, test_dataloader = builder.dataset_builder(Args(), config.dataset.test)
    print(f'Test samples: {len(test_dataloader)}')

    # æ„å»ºæ¨¡å‹
    base_model = builder.model_builder(config.model)

    # åŠ è½½æƒé‡
    state_dict = torch.load(args.ckpt, map_location='cpu')
    if 'base_model' in state_dict:
        model_dict = {k.replace('module.', ''): v for k, v in state_dict['base_model'].items()}
    else:
        model_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
    base_model.load_state_dict(model_dict, strict=False)

    base_model = base_model.to(device)
    base_model = nn.DataParallel(base_model)
    base_model.eval()

    # åˆ›å»º IPGR æ¨¡å—
    ipgr = IPGR(base_alpha=args.base_alpha, num_iter=args.num_iter)

    # è¯„ä¼°æŒ‡æ ‡
    chamfer_l1 = ChamferDistanceL1()
    chamfer_l2 = ChamferDistanceL2()

    cdl1_list = []
    cdl2_list = []

    print('\nTesting...')
    with torch.no_grad():
        for idx, (taxonomy_ids, model_ids, data) in enumerate(test_dataloader):
            try:
                partial = data[0].to(device)
                gt = data[1].to(device)

                # æ¨¡å‹é¢„æµ‹
                pred = base_model(partial)

                # IPGR åå¤„ç†
                if not args.no_ipgr:
                    pred = ipgr(pred, partial)

                # è®¡ç®— Chamfer Distance
                cdl1 = chamfer_l1(pred, gt).item() * 1000
                cdl2 = chamfer_l2(pred, gt).item() * 10000

                cdl1_list.append(cdl1)
                cdl2_list.append(cdl2)

                if (idx + 1) % 1000 == 0:
                    print(f'[{idx + 1}/{len(test_dataloader)}] '
                          f'CDL1: {np.mean(cdl1_list):.3f}, '
                          f'CDL2: {np.mean(cdl2_list):.3f}')

            except Exception as e:
                print(f'Error at {idx}: {e}')
                continue

    # ç»“æœç»Ÿè®¡
    cdl1_arr = np.array(cdl1_list)
    cdl2_arr = np.array(cdl2_list)

    print('\n' + '=' * 70)
    print('RESULTS')
    print('=' * 70)
    print(f'CDL1:       {cdl1_arr.mean():.4f}')
    print(f'CDL2:       {cdl2_arr.mean():.4f}')
    print(f'Median:     {np.median(cdl2_arr):.4f}')
    print(f'Std:        {cdl2_arr.std():.4f}')
    print(f'< 4.0:      {(cdl2_arr < 4).mean() * 100:.1f}%')
    print('=' * 70)

    if cdl2_arr.mean() < 4.0:
        print('ğŸ‰ Target Achieved! (CDL2 < 4.0)')

    return cdl2_arr.mean()


if __name__ == '__main__':
    main()