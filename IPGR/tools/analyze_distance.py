"""
Pred-to-Partial è·ç¦»åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰

åˆ†æ IPGR å‰åé¢„æµ‹ç‚¹åˆ° partial çš„è·ç¦»å˜åŒ–
è¯æ˜ IPGR æœ‰æ•ˆåœ°æ‹‰è¿‘äº†é¢„æµ‹ç‚¹å’Œ partial

ä½¿ç”¨æ–¹æ³•:
    python analyze_distance.py --config cfgs/xxx.yaml --ckpt path/to/ckpt.pth
"""

import torch
import torch.nn as nn
import numpy as np
import argparse
import sys
import os

sys.path.insert(0, os.getcwd())

from tools import builder
from utils.config import cfg_from_yaml_file
from easydict import EasyDict


class IPGR(nn.Module):
    """Iterative Partial-Guided Refinement"""

    def __init__(self, base_alpha=0.05, num_iter=2):
        super().__init__()
        self.base_alpha = base_alpha
        self.num_iter = num_iter

    def forward(self, pred, partial):
        refined = pred.clone()
        B, N, _ = pred.shape
        batch_idx = torch.arange(B, device=pred.device).unsqueeze(1).expand(-1, N)

        for i in range(self.num_iter):
            dist = torch.cdist(refined, partial)
            min_dist, min_idx = dist.min(dim=-1)
            nearest = partial[batch_idx, min_idx]

            dist_norm = min_dist / (min_dist.max(dim=-1, keepdim=True)[0] + 1e-6)
            alpha = self.base_alpha * (2.0 - dist_norm)

            refined = refined + alpha.unsqueeze(-1) * (nearest - refined)

        return refined


def compute_pred_to_partial_distance(pred, partial):
    """
    è®¡ç®—é¢„æµ‹ç‚¹åˆ° partial çš„å¹³å‡æœ€å°è·ç¦»
    """
    dist = torch.cdist(pred, partial)  # [B, N, M]
    min_dist = dist.min(dim=-1)[0]  # [B, N]
    return min_dist.mean(dim=-1)  # [B]


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, required=True)
    parser.add_argument('--ckpt', type=str, required=True)
    parser.add_argument('--num_samples', type=int, default=500, help='æµ‹è¯•æ ·æœ¬æ•°')
    parser.add_argument('--base_alpha', type=float, default=0.05)
    parser.add_argument('--num_iter', type=int, default=2)
    args = parser.parse_args()

    print('=' * 60)
    print('Pred-to-Partial Distance Analysis')
    print('=' * 60)
    print(f'Config: {args.config}')
    print(f'Checkpoint: {args.ckpt}')
    print(f'Samples: {args.num_samples}')
    print('=' * 60)

    # åŠ è½½é…ç½®
    config = cfg_from_yaml_file(args.config)
    config = EasyDict(config)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # æ„å»ºæ•°æ®é›†
    class Args:
        distributed = False
        num_workers = 4

    _, test_dataloader = builder.dataset_builder(Args(), config.dataset.test)
    print(f'Test samples: {len(test_dataloader)}')

    # æ„å»ºæ¨¡å‹
    base_model = builder.model_builder(config.model)

    # åŠ è½½æƒé‡
    state_dict = torch.load(args.ckpt, map_location='cpu')
    if 'base_model' in state_dict:
        model_dict = {k.replace('module.', ''): v for k, v in state_dict['base_model'].items()}
    else:
        model_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
    base_model.load_state_dict(model_dict, strict=False)

    base_model = base_model.to(device)
    base_model = nn.DataParallel(base_model)
    base_model.eval()

    # IPGR æ¨¡å—
    ipgr = IPGR(base_alpha=args.base_alpha, num_iter=args.num_iter)

    # æ”¶é›†è·ç¦»æ•°æ®
    dist_before_list = []
    dist_after_list = []

    print('\nAnalyzing...')
    with torch.no_grad():
        for idx, (taxonomy_ids, model_ids, data) in enumerate(test_dataloader):
            if idx >= args.num_samples:
                break

            partial = data[0].to(device)
            gt = data[1].to(device)

            # æ¨¡å‹é¢„æµ‹
            output = base_model(partial)
            if isinstance(output, tuple):
                pred = output[-1]
            else:
                pred = output

            # IPGR åå¤„ç†
            pred_refined = ipgr(pred, partial)

            # è®¡ç®—è·ç¦»
            dist_before = compute_pred_to_partial_distance(pred, partial)
            dist_after = compute_pred_to_partial_distance(pred_refined, partial)

            dist_before_list.extend(dist_before.cpu().numpy().tolist())
            dist_after_list.extend(dist_after.cpu().numpy().tolist())

            if (idx + 1) % 100 == 0:
                print(f'[{idx + 1}/{args.num_samples}] '
                      f'Before: {np.mean(dist_before_list):.4f}, '
                      f'After: {np.mean(dist_after_list):.4f}')

    # ç»Ÿè®¡ç»“æœ
    dist_before_arr = np.array(dist_before_list)
    dist_after_arr = np.array(dist_after_list)

    print('\n' + '=' * 60)
    print('RESULTS: Pred-to-Partial Distance')
    print('=' * 60)
    print(f'Before IPGR:  {dist_before_arr.mean():.4f} Â± {dist_before_arr.std():.4f}')
    print(f'After IPGR:   {dist_after_arr.mean():.4f} Â± {dist_after_arr.std():.4f}')
    print(f'Reduction:    {(1 - dist_after_arr.mean() / dist_before_arr.mean()) * 100:.1f}%')
    print('=' * 60)

    # åˆ†æ
    print('\nğŸ“Š Analysis:')
    print(f'  â€¢ åŸå§‹é¢„æµ‹ç‚¹åˆ° partial çš„å¹³å‡è·ç¦»: {dist_before_arr.mean():.4f}')
    print(f'  â€¢ IPGR åé¢„æµ‹ç‚¹åˆ° partial çš„å¹³å‡è·ç¦»: {dist_after_arr.mean():.4f}')
    print(f'  â€¢ IPGR æœ‰æ•ˆåœ°å°†é¢„æµ‹ç‚¹æ‹‰è¿‘äº† partial')
    print(f'  â€¢ è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆ IPGR å¯¹è‡ªç›‘ç£æ–¹æ³•æœ‰æ•ˆ:')
    print(f'    - è‡ªç›‘ç£æ–¹æ³•ç¼ºä¹ GT ç›‘ç£ï¼Œé¢„æµ‹ç‚¹å®¹æ˜“åç¦» partial')
    print(f'    - IPGR åˆ©ç”¨ partial ä½œä¸ºå‡ ä½•å…ˆéªŒï¼Œçº æ­£è¿™ç§åç¦»')

    return dist_before_arr.mean(), dist_after_arr.mean()


if __name__ == '__main__':
    main()